{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Relationships Among University of Utah Faculty\n",
    "### &copy; Brian E. Chapman, Ph.D.\n",
    "\n",
    "In this notebook, we will create graphs that shows co-authorship relationships between faculty from either Biomedical Informatics or Human Genetics at the University of Utah. Co-authorship is determined by querying the Pubmed database using the [Biopython](https://github.com/biopython/biopython.github.io/) [Entrez](http://biopython.org/DIST/docs/api/Bio.Entrez-module.html) subpackage. Graphs are created using [NetworkX](https://networkx.github.io/)\n",
    "\n",
    "\n",
    "### Key Concepts\n",
    "#### These concepts and applications might be new to the student.\n",
    "\n",
    "* Graphs\n",
    "* Gzip\n",
    "* Pickle\n",
    "* [set](https://docs.python.org/3.5/tutorial/datastructures.html#sets)\n",
    "* Graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Querying the Entrez Database\n",
    "\n",
    "In this notebook we will be querying papers in the PubMed database. For an example of querying the nucleotide database for a sequence click [here](./BasicEntrezQuery.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The notebook Allows the User to Either create New Pubmed data or use cached results\n",
    "\n",
    "#### Set ``GET_NEW_DATA`` to True to query Entrez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GET_NEW_DATA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "import networkx as nx\n",
    "import os\n",
    "DATADIR = os.path.join(os.path.expanduser(\"~\"),\"DATA\", \"Graphs\")\n",
    "if not GET_NEW_DATA:\n",
    "    DATADIR = os.path.join(os.path.expanduser(\"~\"), \"work\", \"graphs\")\n",
    "    if not os.path.exists(DATADIR):\n",
    "        os.makedirs(DATADIR)\n",
    "    \n",
    "print(os.path.exists(DATADIR))\n",
    "from IPython.display import Image\n",
    "import gzip\n",
    "import pickle\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Faculty Names\n",
    "\n",
    "* Human Genetic faculty names were scrapped from the department website\n",
    "* Biomedical Informatics faculty names were taken from training grant materials\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_faculty = ['Mario Capecchi',\n",
    " 'Richard Cawthon',\n",
    " 'Clement Chow',\n",
    " 'Nels Elde',\n",
    " 'Cedric Feschotte',\n",
    " 'David J. Grunwald',\n",
    " 'Sandra J. Hasstedt',\n",
    " 'Michael T. Howard',\n",
    " 'Lynn B. Jorde',\n",
    " 'Gabrielle Kardon',\n",
    " 'Kristen M. Kwan',\n",
    " 'Mark F. Leppert',\n",
    " 'Anthea Letsou',\n",
    " 'Suzanne L. Mansour',\n",
    " 'Gabor Marth',\n",
    " 'Mark M. Metzstein',\n",
    " 'Charles Murtaugh',\n",
    " 'Ellen J. Pritham',\n",
    " 'Aaron Quinlan',\n",
    " 'Shigeru Sakonju',\n",
    " 'Gillian Stanfield',\n",
    " 'Louisa Stark',\n",
    " 'Carl S. Thummel',\n",
    " 'Robert B. Weiss',\n",
    " 'Mark Yandell']\n",
    "bmi_faculty = ['Samir E AbdelRahman',\n",
    " 'Bruce E Bray',\n",
    " 'Wendy W Chapman',\n",
    " 'Michael A Conway',\n",
    " 'Guilherme Del Fiol',\n",
    " 'Karen Eilbeck',\n",
    " 'R. Scott Evans',\n",
    " 'Julio C Facelli',\n",
    " 'Jennifer H Garvin',\n",
    " 'Bryan S Gibson',\n",
    " 'Ramkiran Gouripeddi',\n",
    " 'Peter J Haug',\n",
    " 'Rachel Hess',\n",
    " 'Stanley M Huff',\n",
    " 'John F Hurdle',\n",
    " 'Kensaku Kawamoto',\n",
    " 'Younghee Lee',\n",
    " 'Gang Luo',\n",
    " 'Stephane M Meystre',\n",
    " 'Scott P Narus',\n",
    " 'Jonathan Nebeker',\n",
    " 'Stephen Piccolo',\n",
    " 'Aaron Quinlan',\n",
    " 'Catherine J Staes',\n",
    " 'Katherine A Sward',\n",
    " 'Charlene R Weir']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Querying Entrez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_first_last(name):\n",
    "    return \" \".join(split_name(name))\n",
    "def split_name(name):\n",
    "    tmp = name.split()\n",
    "    return tmp[0],tmp[-1]\n",
    "def check_author_faculty(author, faculty):\n",
    "    a = split_name(author)\n",
    "    \n",
    "    for f in faculty:\n",
    "        if a[0] in f and a[1] in f:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the pubmed IDs matching query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, email = None):\n",
    "    if email == None:\n",
    "        raise ValueError(\"Must provde a valid e-mail\")\n",
    "    Entrez.email = email\n",
    "    handle = Entrez.esearch(db='pubmed', \n",
    "                            sort='relevance', \n",
    "                            retmax='100',\n",
    "                            retmode='xml', \n",
    "                            term=query)\n",
    "    results = Entrez.read(handle)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch papers corresponding to ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_details(id_list, email=None, retmode='json'):\n",
    "    if email == None:\n",
    "        raise ValueError(\"Must provde a valid e-mail\")\n",
    "    ids = ','.join(id_list)\n",
    "    Entrez.email = email\n",
    "    handle = Entrez.epost(db='pubmed',\n",
    "                           id=ids)\n",
    "    results = Entrez.read(handle)\n",
    "    webenv = results[\"WebEnv\"]\n",
    "    query_key = results[\"QueryKey\"]\n",
    "    fetch_handle = Entrez.efetch(db='pubmed', \n",
    "                                 rettype='xml',\n",
    "                                 retmode=retmode,\n",
    "                                 webenv=webenv, \n",
    "                                 query_key=query_key)\n",
    "    return [r for r in Entrez.read(fetch_handle, validate=False)[\"PubmedArticle\"]]\n",
    "    return fetch_handle.read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Co-authorship\n",
    "\n",
    "Entrez returns a lot of information. We hone it down to just the names. We need to use exceptions because the returned papers doesn't always have the fields we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(Entrez.efetch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coauthor_lists(papers):\n",
    "    paper_authors = {}\n",
    "    for p in papers:\n",
    "        try:\n",
    "            tmp = p['MedlineCitation']\n",
    "            alist = []\n",
    "            for a in tmp['Article']['AuthorList']:\n",
    "                try:\n",
    "                    s = \"%s %s\"%(a['ForeName'],a['LastName'])\n",
    "                    alist.append(s)\n",
    "                except Exception as error:\n",
    "                    pass\n",
    "            paper_authors[tmp['Article']['ArticleTitle']] = alist\n",
    "        except:\n",
    "            pass\n",
    "    return paper_authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_faculty_coauthors(faculty):\n",
    "    return get_coauthor_lists( \n",
    "        fetch_details(search(faculty)['IdList']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faculty_coauthorship(faculty, email=None):\n",
    "    if email == None:\n",
    "        raise ValueError(\"Must provide valid e-mail\")\n",
    "    faculty_ids = {f:search(f, email=email)['IdList'] for f in faculty}\n",
    "    faculty_details_text = {f:fetch_details(ids, retmode='xml', email=email) for f, ids in faculty_ids.items() if ids}\n",
    "    coauthors = {f:get_coauthor_lists(ad) for f, ad in faculty_details_text.items()}\n",
    "    return coauthors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GET_NEW_DATA:\n",
    "    hg_coauthorship = get_faculty_coauthorship(hg_faculty, email=\"brian.chapman@utah.edu\")\n",
    "    bmi_coauthorship = get_faculty_coauthorship(bmi_faculty, email=\"brian.chapman@utah.edu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GET_NEW_DATA:\n",
    "    with gzip.open(os.path.join(DATADIR, \"hg_coauthorship.pickle.gz\"), \"wb\") as f0:\n",
    "        pickle.dump(hg_coauthorship, f0)\n",
    "\n",
    "    with gzip.open(os.path.join(DATADIR, \"bmi_coauthorship.pickle.gz\"), \"wb\") as f0:\n",
    "        pickle.dump(bmi_coauthorship, f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hg_coauthorship"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Data\n",
    "\n",
    "The connection with the Entrez database can be problematic. If you are having difficulty try loading the data I have previously generated. The files are stored in compressed ([gzip](https://en.wikipedia.org/wiki/Gzip)) [pickle](https://docs.python.org/3/library/pickle.html) files. Gzip is a common compression algorithm while pickle is a Python-specific format for writing Python objects to disk. gzipped files can be opened directly by Python and then treated like a normal file. See the documentation for the Python [gzip library](https://docs.python.org/3/library/gzip.html). When I generated the files I used the  [``pickle.dump``](https://docs.python.org/3/library/pickle.html#pickle.dump) function to store ``hg_coauthorship`` and ``bmi_coauthorship`` in individual files.\n",
    "\n",
    "Read the documentation to figure out how to **load** the data back into a Python program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not GET_NEW_DATA:\n",
    "    with gzip.open(os.path.join(DATADIR, \"hg_coauthorship.pickle.gz\"), \"rb\") as f0:\n",
    "        hg_coauthorship = pickle.load(f0)\n",
    "    with gzip.open(os.path.join(DATADIR, \"bmi_coauthorship.pickle.gz\"), \"rb\") as f0:\n",
    "        bmi_coauthorship = pickle.load(f0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Created Undirected Graphs of Co-authorships\n",
    "### We will limit nodes of the graphs to faculty of the department\n",
    "\n",
    "* If we do not add a co-author to the graph we will add them to a list\n",
    "* We will start by creating graphs where we check the author names return from PubMed against the list of faculty names we defined at the top of the notebook.\n",
    "    * We can create either a NetworkX [MultiGraph](https://networkx.github.io/documentation/development/reference/classes.multigraph.html?highlight=multigraph) or a [Graph](https://networkx.github.io/documentation/development/reference/classes.graph.html). A MultiGraph allows for multiple edges (relationships) between nodes (authors), while a Graph allows for only a single edge between two nodes.\n",
    "    * What might be the potential uses of both styles of graphs in an analysis of co-authorships?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_authorship_graph_naive(coauthors, faculty, graph_type = \"multi\"):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    if graph_type == \"multi\":\n",
    "        authorship = nx.MultiGraph()\n",
    "    else:\n",
    "        authorship = nx.Graph()\n",
    "        \n",
    "    not_added = []\n",
    "    faculty_tuples = [split_name(x) for x in faculty]\n",
    "    for author, papers in coauthors.items():\n",
    "        for title, authors in papers.items():\n",
    "            for a in authors:\n",
    "                if a != author:\n",
    "                    if a in faculty:\n",
    "                        authorship.add_edge(author, \n",
    "                                            a, key=title, attr_dict={\"paper\":title})\n",
    "                    else:\n",
    "                        not_added.append(a)\n",
    "    return authorship, not_added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "* ``_``: an underscore is commonly used for a throwaway variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgraphn_hg, not_added_n_hg = create_authorship_graph_naive(hg_coauthorship, hg_faculty)\n",
    "graphn_hg, _ = create_authorship_graph_naive(hg_coauthorship, hg_faculty, graph_type = \"graph\")\n",
    "\n",
    "mgraphn_bmi, not_added_n_bmi = create_authorship_graph_naive(bmi_coauthorship, bmi_faculty)\n",
    "graphn_bmi, _ = create_authorship_graph_naive(bmi_coauthorship, bmi_faculty, graph_type = \"graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the graphs\n",
    "\n",
    "NetworkX has functions for basic descriptions of graphs, such as the number of nodes and number of edges. There are also functions for characterizing the nodes of a graphs, such as the degree (the number of edges connected to a node. We can draw the graphs with matplotlib \n",
    "\n",
    "#### Explore the following drawing functions\n",
    "* ``nx.draw``\n",
    "* ``nx.draw_spring``\n",
    "* ``nx.draw_spectral``\n",
    "* ``nx.draw_circular``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(graphn_hg))\n",
    "print(graphn_hg.number_of_nodes(), graphn_hg.number_of_edges())\n",
    "nx.draw(graphn_hg, with_labels=True, alpha=0.4, font_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(graphn_bmi))\n",
    "print(graphn_bmi.number_of_nodes(), graphn_bmi.number_of_edges())\n",
    "nx.draw_circular(graphn_bmi, with_labels=True, alpha=0.4, font_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw the Graphs with Graphviz\n",
    "\n",
    "While NetworkX comes with a built in Matplotlib drawing interface, it takes a lot of customization to make owrthwhile figures. Instead we will use NetworkX's interface to [graphviz](http://www.graphviz.org/) to generate figures. We will have to save the figures to disk and then use the IPython notebook [``display.Image``](http://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html?highlight=display.image#functions) function to draw the figures in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_graph(g, name):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    ag = nx.nx_pydot.to_pydot(g)\n",
    "    fname = name+\".png\"\n",
    "    ag.write_png(fname)\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(save_graph(mgraphn_hg,\"mgraphn_hg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(save_graph(graphn_hg,\"graphn_hg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(save_graph(mgraphn_bmi,\"mgraphn_bmi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(save_graph(graphn_bmi,\"graphn_bmi\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Our Data\n",
    "\n",
    "The Human Genetics graph seems suspiciously small. We should look at whom we didn't add.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of authors not added to the graph:\", len(not_added_n_hg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors may not have been added to the graph multiple times (a non-faculty author on multiple paper). We can use a Python [set](https://docs.python.org/3.5/tutorial/datastructures.html#sets) to get the unique set of authors not added. For more information about sets click [here](./sets_and_python.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(not_added_n_hg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set of unique authors not added is about half the size of the not added list. This list would consist of students, collaborators from other departments and universities, etc. But is there any chance we didn't add someone we should have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "How would you check whether Mark Yandell was ever incorrectly **not** added?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Better Graph Generation Function\n",
    "\n",
    "One of the challenges we have with our graph generation is that we do not consistently use names. Sometimes I'm \"Brian Chapman\" other times I'm \"Brian E. Chapman\". The same could be true of other authors. If the web page from which I got the faculty names uses names different than how the faculty names appear in PubMed, we would have problems. \n",
    "\n",
    "The most likely problem is with middle names so we could write a function that extracts the first and last name from a name string and we could write another function that checks first names and last names against the list of faculty names (using only the first and last names from that list)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our first/last name checking algorithm we can create a better graph generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_authorship_graph(coauthors, faculty, graph_type = \"multi\"):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    if graph_type == \"multi\":\n",
    "        authorship = nx.MultiGraph()\n",
    "    else:\n",
    "        authorship = nx.Graph()\n",
    "        \n",
    "    not_added = []\n",
    "    faculty_tuples = [split_name(x) for x in faculty]\n",
    "    for author, papers in coauthors.items():\n",
    "        for title, authors in papers.items():\n",
    "            for a in authors:\n",
    "                if join_first_last(a) != join_first_last(author):\n",
    "                    if check_author_faculty(a, faculty_tuples):\n",
    "                        authorship.add_edge(join_first_last(author), \n",
    "                                            join_first_last(a), key=title, attr_dict={\"paper\":title})\n",
    "                    else:\n",
    "                        not_added.append(a)\n",
    "    return authorship, not_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgraph_hg, not_added_hg = create_authorship_graph(hg_coauthorship, hg_faculty)\n",
    "graph_hg, _ = create_authorship_graph(hg_coauthorship, hg_faculty, graph_type = \"graph\")\n",
    "\n",
    "mgraph_bmi, not_added_bmi = create_authorship_graph(bmi_coauthorship, bmi_faculty)\n",
    "graph_bmi, _ = create_authorship_graph(bmi_coauthorship, bmi_faculty, graph_type = \"graph\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of authors not added to the graph:\", len(set(not_added_hg)))\n",
    "print(print(mgraph_hg.number_of_nodes(), mgraph_hg.number_of_edges())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of authors not added to the graph:\", len(set(not_added_bmi)))\n",
    "print(print(mgraph_bmi.number_of_nodes(), mgraph_bmi.number_of_edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(save_graph(mgraph_hg,\"mgraph_hg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(save_graph(graph_hg,\"graph_hg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(save_graph(mgraph_bmi,\"mgraph_bmi\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(save_graph(graph_bmi,\"graph_bmi\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "* Jonathan Nebeker was incorrectly added as a primary faculty in Biomedical Informatics. How can you delete Dr. Nebeker from the graph along with all edges connecting to him?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: How Do the Graphs Compare?\n",
    "\n",
    "* What are the average clustering of the graphs?\n",
    "* What are the diameter of the graphs?\n",
    "* What are the average shortest paths of the graphs?\n",
    "\n",
    "**Hint:** Functions for each of these questions are provided by NetworkX can be found in the [documentation](http://networkx.readthedocs.io/en/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_degrees(g):\n",
    "    gd = [(n,g.degree(n)) for n in g.nodes()]\n",
    "    gd.sort(key = lambda x: x[1], reverse = True)\n",
    "    return gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_graph_node_degree_value(g):\n",
    "    for x in get_graph_degrees(g):\n",
    "        print(\"%s%s\"%((\"%s\"%x[0]).ljust(30),(\"% 2d\"%x[1]).rjust(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_node_degree_value(mgraph_bmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_node_degree_value(mgraph_hg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_node_degree_value(graph_hg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph_node_degree_value(graph_bmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\">University of Uah Data Science for Health</span> by <span xmlns:cc=\"http://creativecommons.org/ns#\" property=\"cc:attributionName\">Brian E. Chapman</span> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
