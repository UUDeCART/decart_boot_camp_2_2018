{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMIC2 Radiology Impression Section Extractor\n",
    "\n",
    "Identify impression section and extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 as sq\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "import zipfile\n",
    "import gzip\n",
    "import os\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = os.path.join(os.path.expanduser(\"~\"),\"Bdrive\",\"Radiology\",\"NLP\",\"DBs\")\n",
    "print(os.path.exists(DATADIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sq.connect(\"./mimic_radreports.sqlite\")\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab the text from the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"\"\"SELECT text FROM reports\"\"\")\n",
    "reports = [r[0].strip() for r in cursor.fetchall()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple regex to identify numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rdigit = re.compile(r\"\"\"\\d\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define code to extract impression section\n",
    "\n",
    "I provide some \"synonyms\" to impression and try splitting report with the prioritized list. To get a sense of the relative importance, I also return what phrase I finally split on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [\"IMPRESSION:\", \"INTERPRETATION:\", \"CONCLUSIONS:\", \"FINDINGS:\"]\n",
    "\n",
    "\n",
    "def get_split_location(report, splits=None):\n",
    "    if splits == None:\n",
    "        splits = [\"IMPRESSION:\", \"INTERPRETATION:\", \"CONCLUSIONS:\", \"FINDINGS:\"]\n",
    "    for s in splits:\n",
    "        try:\n",
    "            return report.index(s),s\n",
    "        except:\n",
    "            pass\n",
    "    return -1,\"NA\"\n",
    "\n",
    "\n",
    "def get_impressions(reports, splits=None):\n",
    "    impression_loc = [get_split_location(r,splits=splits) for r in reports]\n",
    "    return[(d[0][d[1][0]:],d[1]) for d in zip(reports, impression_loc) if d[1][0] != -1]\n",
    "\n",
    "\n",
    "def get_reports(fname=\"pah_mimic2.sqlite\", query=\"\"\"SELECT text FROM mimic_pah_radiology\"\"\"):\n",
    "    \"\"\"My Docstring\"\"\"\n",
    "    conn = sq.connect(os.path.join(DATADIR,fname))\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(query)\n",
    "    return [r[0] for r in cursor.fetchall()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pah_impressions = get_impressions(get_reports(), splits=splits)\n",
    "copd_impressions =get_impressions(get_reports(query=\"\"\"SELECT text FROM mimic_copd_radiology\"\"\"), splits=splits)\n",
    "print(len(pah_impressions))\n",
    "print(len(copd_impressions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What does an impression look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pah_impressions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get ride of our split phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipah = [p[0].split(p[1][1])[1] for p in pah_impressions]\n",
    "icopd = [p[0].split(p[1][1])[1] for p in copd_impressions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipah2 = [ [[w for w in s.words] for s in TextBlob(rdigit.sub(\"\"\"d\"\"\", r.strip().lower())).sentences] for r in ipah]\n",
    "icopd2 = [ [[w for w in s.words] for s in TextBlob(rdigit.sub(\"\"\"d\"\"\", r.strip().lower())).sentences] for r in icopd]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Radiology phrase generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(os.path.join(DATADIR,\"mimic2_demo_n_gram_generators.pickle.gz\"),\"rb\") as f0:\n",
    "    ngp = pickle.load(f0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pah_phrases = [ngp[\"3-gram\"][ngp[\"2-gram\"][s]] for s in ipah2]\n",
    "copd_phrases = [ngp[\"3-gram\"][ngp[\"2-gram\"][s]] for s in icopd2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impression_words_from_phrases(sp):\n",
    "    return [ss for s in sp for ss in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_impression_phrases(sp):\n",
    "    return \" \".join(get_impression_words_from_phrases(sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_impression_phrases(pah_phrases[135])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pah_impression_phrases = [get_impression_words_from_phrases(sp) for sp in pah_phrases]\n",
    "copd_impression_phrases = [get_impression_words_from_phrases(sp) for sp in copd_phrases]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How long is our longest impression section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pah_lengths = [len(i) for i in pah_impression_phrases]\n",
    "copd_lengths = [len(i) for i in copd_impression_phrases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pah_sizes = (np.mean(pah_lengths),np.max(pah_lengths),np.min(pah_lengths))\n",
    "copd_sizes = (np.mean(copd_lengths),np.max(copd_lengths),np.min(copd_lengths))\n",
    "print(pah_sizes,copd_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pah_sizes[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(pah_lengths)\n",
    "sns.distplot(copd_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    #clear_output()\n",
    "    i = int(input(\"Enter sentence #\\n\"))\n",
    "    print(\" \".join(pah_phrases[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in impressions:\n",
    "    try:\n",
    "        clear_output()\n",
    "        print(i[0])\n",
    "        print(i[1])\n",
    "        input('continue')\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Regular expressions for further cleansing\n",
    "\n",
    "Here are some regular expression for finding dates and times. I decided to do a simple conversion from digits to the letter ``d`` leaving everything in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(os.path.join(os.path.expanduser(\"~\"), \n",
    "                            \"Bdrive/Radiology/NLP/DBs\", \n",
    "                            \"mimic2_radsentences.txt.gz\"), \"rt\") as f:\n",
    "    sentences = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pah_impressions = get_impressions(pah_reports)\n",
    "copd_impressions = get_impressions(copd_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [6950]",
   "language": "python",
   "name": "Python [6950]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
